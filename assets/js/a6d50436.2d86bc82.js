"use strict";(self.webpackChunklangflow_docs=self.webpackChunklangflow_docs||[]).push([[5412],{7685:(e,n,t)=>{t.d(n,{A:()=>s});const s=t.p+"assets/images/vector-store-document-ingestion-6157311fb4d16e7f944d55254f0cc0e2.png"},17886:(e,n,t)=>{t.d(n,{A:()=>r});t(96540);var s=t(64058),o=t(74848);function r({name:e,...n}){const t=s[e];return t?(0,o.jsx)(t,{...n}):null}},22444:(e,n,t)=>{t.d(n,{Ay:()=>a,RM:()=>i});var s=t(74848),o=t(28453),r=t(17886);const i=[];function d(e){const n={a:"a",p:"p",strong:"strong",...(0,o.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.p,{children:"By design, vector data is essential for LLM applications, such as chatbots and agents."}),"\n",(0,s.jsx)(n.p,{children:"While you can use an LLM alone for generic chat interactions and common tasks, you can take your application to the next level with context sensitivity (such as RAG) and custom datasets (such as internal business data).\nThis often requires integrating vector databases and vector searches that provide the additional context and define meaningful queries."}),"\n",(0,s.jsx)(n.p,{children:"Langflow includes vector store components that can read and write vector data, including embedding storage, similarity search, Graph RAG traversals, and dedicated search instances like OpenSearch.\nBecause of their interdependent functionality, it is common to use vector store, language model, and embedding model components in the same flow or in a series of dependent flows."}),"\n",(0,s.jsxs)(n.p,{children:["To find available vector store components, browse ",(0,s.jsx)(r.A,{name:"Blocks","aria-hidden":"true"})," ",(0,s.jsx)(n.a,{href:"/components-bundle-components",children:(0,s.jsx)(n.strong,{children:"Bundles"})})," or ",(0,s.jsx)(r.A,{name:"Search","aria-hidden":"true"})," ",(0,s.jsx)(n.strong,{children:"Search"})," for your preferred vector database provider."]})]})}function a(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},27027:(e,n,t)=>{t.d(n,{Ay:()=>a,RM:()=>i});var s=t(74848),o=t(28453),r=t(17886);const i=[];function d(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",img:"img",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.admonition,{type:"tip",children:(0,s.jsxs)(n.p,{children:["For a tutorial that uses vector data in a flow, see ",(0,s.jsx)(n.a,{href:"/chat-with-rag",children:"Create a vector RAG chatbot"}),"."]})}),"\n",(0,s.jsx)(n.p,{children:"The following example demonstrates how to use vector store components in flows alongside related components like embedding model and language model components.\nThese steps walk through important configuration details, functionality, and best practices for using these components effectively.\nThis is only one example; it isn't a prescriptive guide to all possible use cases or configurations."}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Create a flow with the ",(0,s.jsx)(n.strong,{children:"Vector Store RAG"})," template."]}),"\n",(0,s.jsxs)(n.p,{children:["This template has two subflows.\nThe ",(0,s.jsx)(n.strong,{children:"Load Data"})," subflow loads embeddings and content into a vector database, and the ",(0,s.jsx)(n.strong,{children:"Retriever"})," subflow runs a vector search to retrieve relevant context based on a user's query."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Configure the database connection for both ",(0,s.jsxs)(n.a,{href:"/bundles-datastax#astra-db",children:[(0,s.jsx)(n.strong,{children:"Astra DB"})," components"]}),", or replace them with another pair of vector store components of your choice.\nMake sure the components connect to the same vector store, and that the component in the ",(0,s.jsx)(n.strong,{children:"Retriever"})," subflow is able to run a similarity search."]}),"\n",(0,s.jsxs)(n.p,{children:["The parameters you set in each vector store component depend on the component's role in your flow.\nIn this example, the ",(0,s.jsx)(n.strong,{children:"Load Data"})," subflow ",(0,s.jsx)(n.em,{children:"writes"})," to the vector store, whereas the ",(0,s.jsx)(n.strong,{children:"Retriever"})," subflow ",(0,s.jsx)(n.em,{children:"reads"})," from the vector store.\nTherefore, search-related parameters are only relevant to the ",(0,s.jsx)(n.strong,{children:"Vector Search"})," component in the ",(0,s.jsx)(n.strong,{children:"Retriever"})," subflow."]}),"\n",(0,s.jsx)(n.p,{children:"For information about specific parameters, see the documentation for your chosen vector store component."}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"To configure the embedding model, do one of the following:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Use an OpenAI model"}),": In both ",(0,s.jsx)(n.strong,{children:"OpenAI Embeddings"})," components, enter your OpenAI API key.\nYou can use the default model or select a different OpenAI embedding model."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Use another provider"}),": Replace the ",(0,s.jsx)(n.strong,{children:"OpenAI Embeddings"})," components with another pair of ",(0,s.jsx)(n.a,{href:"/components-embedding-models",children:"embedding model components"})," of your choice, and then configure the parameters and credentials accordingly."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Use Astra DB vectorize"}),": If you are using an Astra DB vector store that has a vectorize integration, you can remove both ",(0,s.jsx)(n.strong,{children:"OpenAI Embeddings"})," components.\nIf you do this, the vectorize integration automatically generates embeddings from the ",(0,s.jsx)(n.strong,{children:"Ingest Data"})," (in the ",(0,s.jsx)(n.strong,{children:"Load Data"})," subflow) and ",(0,s.jsx)(n.strong,{children:"Search Query"})," (in the ",(0,s.jsx)(n.strong,{children:"Retriever"})," subflow)."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.admonition,{type:"tip",children:(0,s.jsx)(n.p,{children:"If your vector store already contains embeddings, make sure your embedding model components use the same model as your previous embeddings.\nMixing embedding models in the same vector store can produce inaccurate search results."})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Recommended: In the ",(0,s.jsxs)(n.a,{href:"/components-processing#split-text",children:[(0,s.jsx)(n.strong,{children:"Split Text"})," component"]}),", optimize the chunking settings for your embedding model.\nFor example, if your embedding model has a token limit of 512, then the ",(0,s.jsx)(n.strong,{children:"Chunk Size"})," parameter must not exceed that limit."]}),"\n",(0,s.jsxs)(n.p,{children:["Additionally, because the ",(0,s.jsx)(n.strong,{children:"Retriever"})," subflow passes the chat input directly to the vector store component for vector search, make sure that your chat input string doesn't exceed your embedding model's limits.\nFor this example, you can enter a query that is within the limits; however, in a production environment, you might need to implement additional checks or preprocessing steps to ensure compliance.\nFor example, use additional components to prepare the chat input before running the vector search, or enforce chat input limits in your application code."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["In the ",(0,s.jsx)(n.strong,{children:"Language Model"})," component, enter your OpenAI API key, or select a different provider and model to use for the chat portion of the flow."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Run the ",(0,s.jsx)(n.strong,{children:"Load Data"})," subflow to populate your vector store.\nIn the ",(0,s.jsx)(n.strong,{children:"File"})," component, select one or more files, and then click ",(0,s.jsx)(r.A,{name:"Play","aria-hidden":"true"})," ",(0,s.jsx)(n.strong,{children:"Run component"})," on the vector store component in the ",(0,s.jsx)(n.strong,{children:"Load Data"})," subflow."]}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.strong,{children:"Load Data"})," subflow loads files from your local machine, chunks them, generates embeddings for the chunks, and then stores the chunks and their embeddings in the vector database."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"Embedding data into a vector store",src:t(7685).A+"",width:"4000",height:"2512"})}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.strong,{children:"Load Data"})," subflow is separate from the ",(0,s.jsx)(n.strong,{children:"Retriever"})," subflow because you probably won't run it every time you use the chat.\nYou can run the ",(0,s.jsx)(n.strong,{children:"Load Data"})," subflow as needed to preload or update the data in your vector store.\nThen, your chat interactions only use the components that are necessary for chat."]}),"\n",(0,s.jsxs)(n.p,{children:["If your vector store already contains data that you want to use for vector search, then you don't need to run the ",(0,s.jsx)(n.strong,{children:"Load Data"})," subflow."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Open the ",(0,s.jsx)(n.strong,{children:"Playground"})," and start chatting to run the ",(0,s.jsx)(n.strong,{children:"Retriever"})," subflow."]}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.strong,{children:"Retriever"})," subflow generates an embedding from chat input, runs a vector search to retrieve similar content from your vector store, parses the search results into supplemental context for the LLM, and then uses the LLM to generate a natural language response to your query.\nThe LLM uses the vector search results along with its internal training data and tools, such as basic web search and datetime information, to produce the response."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"Retrieval from a vector store",src:t(67719).A+"",width:"4000",height:"1324"})}),"\n",(0,s.jsxs)(n.p,{children:["To avoid passing the entire block of raw search results to the LLM, the ",(0,s.jsx)(n.strong,{children:"Parser"})," component extracts ",(0,s.jsx)(n.code,{children:"text"})," strings from the search results ",(0,s.jsx)(n.code,{children:"Data"})," object, and then passes them to the ",(0,s.jsx)(n.strong,{children:"Prompt Template"})," component in ",(0,s.jsx)(n.code,{children:"Message"})," format.\nFrom there, the strings and other template content are compiled into natural language instructions for the LLM."]}),"\n",(0,s.jsxs)(n.p,{children:["You can use other components for this transformation, such as the ",(0,s.jsx)(n.strong,{children:"Data Operations"})," component, depending on how you want to use the search results."]}),"\n",(0,s.jsxs)(n.p,{children:["To view the raw search results, click ",(0,s.jsx)(r.A,{name:"TextSearch","aria-hidden":"true"})," ",(0,s.jsx)(n.strong,{children:"Inspect output"})," on the vector store component after running the ",(0,s.jsx)(n.strong,{children:"Retriever"})," subflow."]}),"\n"]}),"\n"]})]})}function a(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},31929:(e,n,t)=>{t.d(n,{Ay:()=>a,RM:()=>i});var s=t(74848),o=t(28453),r=t(17886);const i=[];function d(e){const n={a:"a",p:"p",strong:"strong",...(0,o.R)(),...e.components};return(0,s.jsxs)(n.p,{children:["Some parameters are hidden by default in the visual editor.\nYou can modify all parameters through the ",(0,s.jsx)(r.A,{name:"SlidersHorizontal","aria-hidden":"true"})," ",(0,s.jsx)(n.strong,{children:"Controls"})," in the ",(0,s.jsx)(n.a,{href:"/concepts-components#component-menus",children:"component's header menu"}),"."]})}function a(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},51993:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>m,contentTitle:()=>h,default:()=>x,frontMatter:()=>l,metadata:()=>s,toc:()=>p});const s=JSON.parse('{"id":"Components/components-embedding-models","title":"Embedding Model","description":"Embedding model components in Langflow generate text embeddings using a specified Large Language Model (LLM).","source":"@site/docs/Components/components-embedding-models.mdx","sourceDirName":"Components","slug":"/components-embedding-models","permalink":"/components-embedding-models","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"Embedding Model","slug":"/components-embedding-models"},"sidebar":"docs","previous":{"title":"Language Model","permalink":"/components-models"},"next":{"title":"Data","permalink":"/components-data"}}');var o=t(74848),r=t(28453),i=t(17886),d=t(31929),a=t(22444),c=t(27027);const l={title:"Embedding Model",slug:"/components-embedding-models"},h=void 0,m={},p=[{value:"Use embedding model components in a flow",id:"use-embedding-model-components-in-a-flow",level:2},{value:"Embedding Model parameters",id:"embedding-model-parameters",level:2},...d.RM,{value:"Additional embedding models",id:"additional-embedding-models",level:2},{value:"Pair models with vector stores",id:"pair-models-with-vector-stores",level:2},...a.RM,...c.RM];function u(e){const n={a:"a",admonition:"admonition",code:"code",h2:"h2",img:"img",li:"li",ol:"ol",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components},{Details:s}=n;return s||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.p,{children:"Embedding model components in Langflow generate text embeddings using a specified Large Language Model (LLM)."}),"\n",(0,o.jsxs)(n.p,{children:["Langflow includes an ",(0,o.jsx)(n.strong,{children:"Embedding Model"})," core component that has built-in support for some LLMs.\nAlternatively, you can use any ",(0,o.jsx)(n.a,{href:"#additional-embedding-models",children:"additional embedding model"})," in place of the ",(0,o.jsx)(n.strong,{children:"Embedding Model"})," core component."]}),"\n",(0,o.jsx)(n.h2,{id:"use-embedding-model-components-in-a-flow",children:"Use embedding model components in a flow"}),"\n",(0,o.jsx)(n.p,{children:"Use embedding model components anywhere you need to generate embeddings in a flow."}),"\n",(0,o.jsx)(n.p,{children:"This example shows how to use an embedding model component in a flow to create a semantic search system.\nThis flow loads a text file, splits the text into chunks, generates embeddings for each chunk, and then loads the chunks and embeddings into a vector store. The input and output components allow a user to query the vector store through a chat interface."}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.img,{alt:"A semantic search flow that uses Embedding Model, File, Split Text, Chroma DB, Chat Input, and Chat Output components",src:t(54016).A+"",width:"4000",height:"2514"})}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:["Create a flow, add a ",(0,o.jsx)(n.strong,{children:"File"})," component, and then select a file containing text data, such as a PDF, that you can use to test the flow."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:["Add the ",(0,o.jsx)(n.strong,{children:"Embedding Model"})," core component, and then provide a valid OpenAI API key.\nYou can enter the API key directly or use a ",(0,o.jsx)(i.A,{name:"Globe","aria-hidden":"true"})," ",(0,o.jsx)(n.a,{href:"/configuration-global-variables",children:"global variable"}),"."]}),"\n",(0,o.jsxs)(n.admonition,{title:"My preferred provider or model isn't listed",type:"tip",children:[(0,o.jsxs)(n.p,{children:["If your preferred embedding model provider or model isn't supported by the ",(0,o.jsx)(n.strong,{children:"Embedding Model"})," core component, you can use any ",(0,o.jsx)(n.a,{href:"#additional-embedding-models",children:"additional embedding models"})," in place of the core component."]}),(0,o.jsxs)(n.p,{children:["Browse ",(0,o.jsx)(i.A,{name:"Blocks","aria-hidden":"true"})," ",(0,o.jsx)(n.a,{href:"/components-bundle-components",children:(0,o.jsx)(n.strong,{children:"Bundles"})})," or ",(0,o.jsx)(i.A,{name:"Search","aria-hidden":"true"})," ",(0,o.jsx)(n.strong,{children:"Search"})," for your preferred provider to find additional embedding models, such as the ",(0,o.jsxs)(n.a,{href:"/bundles-huggingface#hugging-face-embeddings-inference",children:[(0,o.jsx)(n.strong,{children:"Hugging Face Embeddings Inference"})," component"]}),"."]})]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:["Add a ",(0,o.jsxs)(n.a,{href:"/components-processing#split-text",children:[(0,o.jsx)(n.strong,{children:"Split Text"})," component"]})," to your flow.\nThis component splits text input into smaller chunks to be processed into embeddings."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:["Add a vector store component, such as the ",(0,o.jsx)(n.strong,{children:"Chroma DB"})," component, to your flow, and then configure the component to connect to your vector database.\nThis component stores the generated embeddings so they can be used for similarity search."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Connect the components:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["Connect the ",(0,o.jsx)(n.strong,{children:"File"})," component's ",(0,o.jsx)(n.strong,{children:"Loaded Files"})," output to the ",(0,o.jsx)(n.strong,{children:"Split Text"})," component's ",(0,o.jsx)(n.strong,{children:"Data or DataFrame"})," input."]}),"\n",(0,o.jsxs)(n.li,{children:["Connect the ",(0,o.jsx)(n.strong,{children:"Split Text"})," component's ",(0,o.jsx)(n.strong,{children:"Chunks"})," output to the vector store component's ",(0,o.jsx)(n.strong,{children:"Ingest Data"})," input."]}),"\n",(0,o.jsxs)(n.li,{children:["Connect the ",(0,o.jsx)(n.strong,{children:"Embedding Model"})," component's ",(0,o.jsx)(n.strong,{children:"Embeddings"})," output to the vector store component's ",(0,o.jsx)(n.strong,{children:"Embedding"})," input."]}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:["To query the vector store, add ",(0,o.jsxs)(n.a,{href:"/components-io#chat-io",children:[(0,o.jsx)(n.strong,{children:"Chat Input and Output"})," components"]}),":"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["Connect the ",(0,o.jsx)(n.strong,{children:"Chat Input"})," component to the vector store component's ",(0,o.jsx)(n.strong,{children:"Search Query"})," input."]}),"\n",(0,o.jsxs)(n.li,{children:["Connect the vector store component's ",(0,o.jsx)(n.strong,{children:"Search Results"})," output to the ",(0,o.jsx)(n.strong,{children:"Chat Output"})," component."]}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:["Click ",(0,o.jsx)(n.strong,{children:"Playground"}),", and then enter a search query to retrieve text chunks that are most semantically similar to your query."]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"embedding-model-parameters",children:"Embedding Model parameters"}),"\n",(0,o.jsxs)(n.p,{children:["The following parameters are for the ",(0,o.jsx)(n.strong,{children:"Embedding Model"})," core component.\nOther embedding model components can have additional or different parameters."]}),"\n","\n",(0,o.jsx)(d.Ay,{}),"\n",(0,o.jsxs)(n.table,{children:[(0,o.jsx)(n.thead,{children:(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.th,{children:"Name"}),(0,o.jsx)(n.th,{children:"Display Name"}),(0,o.jsx)(n.th,{children:"Type"}),(0,o.jsx)(n.th,{children:"Description"})]})}),(0,o.jsxs)(n.tbody,{children:[(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:"provider"}),(0,o.jsx)(n.td,{children:"Model Provider"}),(0,o.jsx)(n.td,{children:"List"}),(0,o.jsx)(n.td,{children:"Input parameter. Select the embedding model provider."})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:"model"}),(0,o.jsx)(n.td,{children:"Model Name"}),(0,o.jsx)(n.td,{children:"List"}),(0,o.jsx)(n.td,{children:"Input parameter. Select the embedding model to use."})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:"api_key"}),(0,o.jsx)(n.td,{children:"OpenAI API Key"}),(0,o.jsx)(n.td,{children:"Secret[String]"}),(0,o.jsx)(n.td,{children:"Input parameter. The API key required for authenticating with the provider."})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:"api_base"}),(0,o.jsx)(n.td,{children:"API Base URL"}),(0,o.jsx)(n.td,{children:"String"}),(0,o.jsx)(n.td,{children:"Input parameter. Base URL for the API. Leave empty for default."})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:"dimensions"}),(0,o.jsx)(n.td,{children:"Dimensions"}),(0,o.jsx)(n.td,{children:"Integer"}),(0,o.jsx)(n.td,{children:"Input parameter. The number of dimensions for the output embeddings."})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:"chunk_size"}),(0,o.jsx)(n.td,{children:"Chunk Size"}),(0,o.jsx)(n.td,{children:"Integer"}),(0,o.jsxs)(n.td,{children:["Input parameter. The size of text chunks to process. Default: ",(0,o.jsx)(n.code,{children:"1000"}),"."]})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:"request_timeout"}),(0,o.jsx)(n.td,{children:"Request Timeout"}),(0,o.jsx)(n.td,{children:"Float"}),(0,o.jsx)(n.td,{children:"Input parameter. Timeout for API requests."})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:"max_retries"}),(0,o.jsx)(n.td,{children:"Max Retries"}),(0,o.jsx)(n.td,{children:"Integer"}),(0,o.jsxs)(n.td,{children:["Input parameter. Maximum number of retry attempts. Default: ",(0,o.jsx)(n.code,{children:"3"}),"."]})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:"show_progress_bar"}),(0,o.jsx)(n.td,{children:"Show Progress Bar"}),(0,o.jsx)(n.td,{children:"Boolean"}),(0,o.jsx)(n.td,{children:"Input parameter. Whether to display a progress bar during embedding generation."})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:"model_kwargs"}),(0,o.jsx)(n.td,{children:"Model Kwargs"}),(0,o.jsx)(n.td,{children:"Dictionary"}),(0,o.jsx)(n.td,{children:"Input parameter. Additional keyword arguments to pass to the model."})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:"embeddings"}),(0,o.jsx)(n.td,{children:"Embeddings"}),(0,o.jsx)(n.td,{children:"Embeddings"}),(0,o.jsx)(n.td,{children:"Output parameter. An instance for generating embeddings using the selected provider."})]})]})]}),"\n",(0,o.jsx)(n.h2,{id:"additional-embedding-models",children:"Additional embedding models"}),"\n",(0,o.jsxs)(n.p,{children:["If your provider or model isn't supported by the ",(0,o.jsx)(n.strong,{children:"Embedding Model"})," core component, you can replace this component with any other component that generates embeddings."]}),"\n",(0,o.jsxs)(n.p,{children:["To find additional embedding model components, browse ",(0,o.jsx)(i.A,{name:"Blocks","aria-hidden":"true"})," ",(0,o.jsx)(n.a,{href:"/components-bundle-components",children:(0,o.jsx)(n.strong,{children:"Bundles"})})," or ",(0,o.jsx)(i.A,{name:"Search","aria-hidden":"true"})," ",(0,o.jsx)(n.strong,{children:"Search"})," for your preferred provider."]}),"\n",(0,o.jsx)(n.h2,{id:"pair-models-with-vector-stores",children:"Pair models with vector stores"}),"\n","\n",(0,o.jsx)(a.Ay,{}),"\n",(0,o.jsxs)(s,{children:[(0,o.jsx)("summary",{children:"Example: Vector search flow"}),(0,o.jsx)(c.Ay,{})]})]})}function x(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(u,{...e})}):u(e)}},54016:(e,n,t)=>{t.d(n,{A:()=>s});const s=t.p+"assets/images/component-embedding-models-add-chat-fec505c7d61c7bddc37eeb1d4cb9d489.png"},67719:(e,n,t)=>{t.d(n,{A:()=>s});const s=t.p+"assets/images/vector-store-retrieval-af7257d77ff0259ab1a0980641d464ce.png"}}]);